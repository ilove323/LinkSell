"""
LinkSell å‘é‡æ•°æ®åº“æœåŠ¡ (RAG Core)

èŒè´£ï¼š
- ç®¡ç†æœ¬åœ°å‘é‡æ•°æ®åº“ (ChromaDB) çš„ç”Ÿå‘½å‘¨æœŸ
- å°†éç»“æ„åŒ–å•†æœºæ•°æ®è½¬åŒ–ä¸ºå‘é‡ (Embedding)
- æä¾›åŸºäºè¯­ä¹‰çš„æ¨¡ç³Šæœç´¢ä¸åŸºäºå­—æ®µçš„ç²¾ç¡®è¿‡æ»¤

ç‰¹ç‚¹ï¼š
- **Hybrid Search**: æ”¯æŒ"è¯­ä¹‰ç›¸ä¼¼åº¦ + å…ƒæ•°æ®è¿‡æ»¤"çš„æ··åˆæ£€ç´¢
- **Async Loading**: é‡‡ç”¨åå°çº¿ç¨‹åŠ è½½æ¨¡å‹ï¼Œé¿å…é˜»å¡ä¸»ç¨‹åºå¯åŠ¨
- **Metadata Extraction**: è‡ªåŠ¨æ‹†åˆ†å…³é”®å­—æ®µ (é”€å”®ã€é˜¶æ®µç­‰) ç”¨äºç²¾ç¡®ç­›é€‰
"""

import os
import threading
import json
from pathlib import Path

# [ç¯å¢ƒé…ç½®] å¿…é¡»åœ¨å¯¼å…¥ sentence_transformers ä¹‹å‰è®¾ç½®
# ä½œç”¨ï¼šå¼ºåˆ¶ä½¿ç”¨ HF å›½å†…é•œåƒï¼Œé˜²æ­¢ä¸‹è½½æ¨¡å‹æ—¶è¶…æ—¶ï¼›æ¸…é™¤ä»£ç†é˜²æ­¢è¿æ¥é”™è¯¯
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
os.environ["HTTP_PROXY"] = ""
os.environ["HTTPS_PROXY"] = ""

import chromadb
from sentence_transformers import SentenceTransformer

class VectorService:
    def __init__(self, db_path="data/vector_db", model_name="paraphrase-multilingual-MiniLM-L12-v2"):
        """
        [åˆå§‹åŒ–] å¯åŠ¨åå°åŠ è½½çº¿ç¨‹
        
        å‚æ•°:
        - db_path: å‘é‡æ•°æ®åº“çš„æœ¬åœ°å­˜å‚¨è·¯å¾„
        - model_name: ä½¿ç”¨çš„ Embedding æ¨¡å‹åç§° (é»˜è®¤å¤šè¯­è¨€å°æ¨¡å‹)
        """
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self.model_name = model_name
        
        # [å†…éƒ¨çŠ¶æ€]
        self.model = None       # Embedding æ¨¡å‹å®ä¾‹
        self.client = None      # ChromaDB å®¢æˆ·ç«¯
        self.collection = None  # ChromaDB é›†åˆ (Table)
        
        # [çº¿ç¨‹æ§åˆ¶] ç”¨äºåŒæ­¥ä¸»çº¿ç¨‹å’ŒåŠ è½½çº¿ç¨‹
        self._init_event = threading.Event()
        self._init_error = None
        
        # [å¯åŠ¨åå°çº¿ç¨‹]
        # è¿™æ ·ä¸»ç¨‹åºå¯ä»¥ç«‹åˆ»å¯åŠ¨ UIï¼Œä¸ç”¨ç­‰æ¨¡å‹åŠ è½½å®Œ
        print("ğŸš€ [VectorService] å¯åŠ¨åå°åŠ è½½çº¿ç¨‹...")
        loader_thread = threading.Thread(target=self._background_loader, daemon=True)
        loader_thread.start()

    def _background_loader(self):
        """
        [åå°ä»»åŠ¡] æ‰§è¡Œè€—æ—¶çš„æ¨¡å‹åŠ è½½å’Œæ•°æ®åº“è¿æ¥
        """
        try:
            print("â³ [VectorService] åå°æ­£åœ¨åŠ è½½ Embedding æ¨¡å‹...")
            # 1. åŠ è½½ HuggingFace æ¨¡å‹ (ç¬¬ä¸€æ¬¡ä¼šä¸‹è½½ï¼Œæ¯”è¾ƒæ…¢)
            self.model = SentenceTransformer(self.model_name)
            
            print("â³ [VectorService] åå°æ­£åœ¨è¿æ¥ ChromaDB...")
            # 2. åˆå§‹åŒ–æŒä¹…åŒ–å‘é‡æ•°æ®åº“
            self.client = chromadb.PersistentClient(path=str(self.db_path))
            # è·å–æˆ–åˆ›å»ºåä¸º 'sales_knowledge' çš„é›†åˆ
            self.collection = self.client.get_or_create_collection(name="sales_knowledge")
            
            print("âœ… [VectorService] å‘é‡å¼•æ“åå°åŠ è½½å®Œæˆï¼")
        except Exception as e:
            print(f"âŒ [VectorService] åˆå§‹åŒ–å¤±è´¥: {e}")
            self._init_error = e
        finally:
            # æ— è®ºæˆåŠŸå¤±è´¥ï¼Œéƒ½è®¾ç½® Eventï¼Œé€šçŸ¥ä¸»çº¿ç¨‹ç­‰å¾…ç»“æŸ
            self._init_event.set()

    def _ensure_initialized(self, timeout: float = 30.0):
        """
        [çŠ¶æ€å®ˆå«] ç¡®ä¿æœåŠ¡å·²å°±ç»ª
        å¦‚æœä¸»çº¿ç¨‹åœ¨åå°åŠ è½½å®Œæˆå‰è°ƒç”¨äº†æ–¹æ³•ï¼Œè¿™é‡Œä¼šé˜»å¡ç­‰å¾…ã€‚

        å‚æ•°:
        - timeout: æœ€å¤§ç­‰å¾…æ—¶é—´(ç§’)ï¼Œé˜²æ­¢æ— é™é˜»å¡
        """
        if not self._init_event.is_set():
            print(f"âš ï¸ [VectorService] è¯·æ±‚è¿‡æ—©ï¼Œæ­£åœ¨ç­‰å¾…æœ€å¤š {timeout}s å¼•æ“å°±ç»ª...")
            if not self._init_event.wait(timeout=timeout):
                raise TimeoutError(f"VectorService åˆå§‹åŒ–è¶…æ—¶ ({timeout}s)")

        if self._init_error:
            raise RuntimeError(f"VectorService failed to initialize: {self._init_error}")

    def status(self):
        """æ£€æŸ¥å½“å‰æœåŠ¡çŠ¶æ€ (ç”¨äº UI å±•ç¤º)"""
        if self._init_error:
            return "Error"
        return "Ready" if self._init_event.is_set() else "Loading..."

    def _format_record(self, record: dict) -> str:
        """
        [æ•°æ®å¤„ç†] å°† JSON ç»“æ„åŒ–æ•°æ®è½¬æ¢ä¸ºç”¨äº Embedding çš„çº¯æ–‡æœ¬
        è¿™æ˜¯ RAG çš„å…³é”®ï¼šæŠŠåˆ†æ•£çš„å­—æ®µæ‹¼æ¥æˆä¸€æ®µæœ‰æ„ä¹‰çš„è¯ã€‚
        """
        cust = record.get("customer_info", {})
        opp = record.get("project_opportunity", {})
        
        text = f"è®°å½•ç±»å‹: {record.get('record_type')}; "
        text += f"é”€å”®: {record.get('sales_rep')}; "
        text += f"æ‘˜è¦: {record.get('summary')}; "
        text += f"å®¢æˆ·: {cust.get('name')} æ¥è‡ª {cust.get('company')}; "
        text += f"é¡¹ç›®: {opp.get('project_name')} é¢„ç®— {opp.get('budget')} é˜¶æ®µ {opp.get('stage')}; "
        text += f"å…³é”®ç‚¹: {', '.join(record.get('key_points', []))}"
        return text

    def add_record(self, record_id: int, record_data: dict, timeout: float = 30.0):
        """
        [æ ¸å¿ƒåŠŸèƒ½] æ·»åŠ æˆ–æ›´æ–°ä¸€æ¡è®°å½•

        å‚æ•°:
        - timeout: åˆå§‹åŒ–è¶…æ—¶æ—¶é—´(ç§’)
        """
        self._ensure_initialized(timeout=timeout) # ç¡®ä¿å°±ç»ª
        
        # 1. ç”Ÿæˆå†…å®¹å‘é‡
        content_text = self._format_record(record_data)
        embedding = self.model.encode(content_text).tolist()
        
        # 2. [å…ƒæ•°æ®æå–] (Metadata Extraction)
        # å°†å…³é”®å­—æ®µå•ç‹¬æ‹†åˆ†å­˜å…¥ metadataï¼Œä»¥ä¾¿åç»­ä½¿ç”¨ where è¯­å¥è¿›è¡Œç²¾ç¡®è¿‡æ»¤
        # æ³¨æ„ï¼šChroma çš„ metadata åªèƒ½å­˜ç®€å•ç±»å‹ (str, int, float, bool)
        
        # æå–é¡¹ç›®å (å…¼å®¹å¤šå±‚çº§)
        p_name = record_data.get("project_opportunity", {}).get("project_name")
        if not p_name: p_name = record_data.get("project_name", "æœªå‘½å")
        
        # æå–é˜¶æ®µ
        stage = record_data.get("opportunity_stage")
        if not stage: stage = record_data.get("project_opportunity", {}).get("opportunity_stage", "")
        
        meta = {
            "json_data": json.dumps(record_data, ensure_ascii=False), # å­˜å®Œæ•´ JSON æ–¹ä¾¿è¿˜åŸ
            "sales_rep": str(record_data.get("sales_rep", "æœªçŸ¥")),  # <--- é”€å”®è¿‡æ»¤çš„å…³é”®
            "record_type": str(record_data.get("record_type", "å•†æœº")),
            "project_name": str(p_name),
            "stage": str(stage)
        }

        # 3. å­˜å…¥æ•°æ®åº“ (Upsert: å­˜åœ¨åˆ™æ›´æ–°ï¼Œä¸å­˜åœ¨åˆ™æ’å…¥)
        self.collection.upsert(
            embeddings=[embedding],
            documents=[content_text],
            metadatas=[meta],
            ids=[str(record_id)]
        )

    def delete_record(self, record_id: str, timeout: float = 30.0):
        """
        [æ ¸å¿ƒåŠŸèƒ½] åˆ é™¤æŒ‡å®šè®°å½•

        å‚æ•°:
        - timeout: åˆå§‹åŒ–è¶…æ—¶æ—¶é—´(ç§’)
        """
        self._ensure_initialized(timeout=timeout)
        try:
            self.collection.delete(ids=[str(record_id)])
            return True
        except Exception as e:
            # åˆ é™¤å¤±è´¥é€šå¸¸ä¸å½±å“ä¸»æµç¨‹ï¼Œè®°å½•å³å¯
            return False

    def reset_db(self, timeout: float = 30.0):
        """
        [å±é™©æ“ä½œ] æ¸…ç©ºæ‰€æœ‰æ•°æ®

        å‚æ•°:
        - timeout: åˆå§‹åŒ–è¶…æ—¶æ—¶é—´(ç§’)
        """
        self._ensure_initialized(timeout=timeout)
        try:
            self.client.delete_collection("sales_knowledge")
            self.collection = self.client.get_or_create_collection(name="sales_knowledge")
            return True
        except Exception as e:
            print(f"Reset failed: {e}")
            return False

    def search(self, query: str, top_k=5, where_filter: dict = None, timeout: float = 30.0):
        """
        [æ ¸å¿ƒåŠŸèƒ½] è¯­ä¹‰æœç´¢

        å‚æ•°:
        - query: ç”¨æˆ·çš„é—®é¢˜æˆ–æœç´¢è¯
        - top_k: è¿”å›æœ€ç›¸ä¼¼çš„å‰ K æ¡
        - where_filter: è¿‡æ»¤æ¡ä»¶ (ä¾‹å¦‚ {"sales_rep": "å¼ ä¸‰"})
        - timeout: åˆå§‹åŒ–è¶…æ—¶æ—¶é—´(ç§’)
        """
        self._ensure_initialized(timeout=timeout)
        
        # 1. å°†æŸ¥è¯¢è¯è½¬æ¢ä¸ºå‘é‡
        query_embedding = self.model.encode(query).tolist()
        
        # 2. åœ¨æ•°æ®åº“ä¸­æ‰§è¡Œå‘é‡è¿‘é‚»æœç´¢
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            where=where_filter  # <--- ç²¾ç¡®è¿‡æ»¤æ¡ä»¶
        )
        
        # 3. è§£æç»“æœï¼Œæå–åŸå§‹ JSON æ•°æ®
        history_snippets = []
        if results and "metadatas" in results:
            for meta_list in results["metadatas"]:
                for meta in meta_list:
                    # ä» metadata ä¸­è¿˜åŸå®Œæ•´çš„ JSON å¯¹è±¡
                    history_snippets.append(json.loads(meta["json_data"]))
        return history_snippets

    def search_projects(self, project_name: str, top_k=3, threshold=1.2, timeout: float = 30.0):
        """
        [ä¸“ç”¨åŠŸèƒ½] é¡¹ç›®åç›¸ä¼¼åº¦æœç´¢
        ç”¨äºæ£€æŸ¥é¡¹ç›®æ˜¯å¦å·²å­˜åœ¨ï¼Œæˆ–è€…æ ¹æ®æ¨¡ç³Šåç§°æ‰¾é¡¹ç›®ã€‚

        å‚æ•°:
        - threshold: è·ç¦»é˜ˆå€¼ (L2è·ç¦»)ã€‚è¶Šå°è¶Šç›¸ä¼¼ï¼Œè¶…è¿‡æ­¤å€¼åˆ™ä¸¢å¼ƒã€‚
        - timeout: åˆå§‹åŒ–è¶…æ—¶æ—¶é—´(ç§’)
        """
        self._ensure_initialized(timeout=timeout)
        query_embedding = self.model.encode(project_name).tolist()
        
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
        )
        
        matches = []
        if results and "metadatas" in results:
            ids = results["ids"][0]
            metadatas = results["metadatas"][0]
            # è·å–è·ç¦» (0=å®Œå…¨ä¸€è‡´)
            distances = results["distances"][0] if "distances" in results else [0]*len(ids)
            
            for rid, meta, dist in zip(ids, metadatas, distances):
                # è¿‡æ»¤æ‰è·ç¦»å¤ªè¿œçš„ç»“æœ (ä¸ç›¸å…³)
                if dist > threshold:
                    continue

                try:
                    data = json.loads(meta["json_data"])
                    p_name = data.get("project_opportunity", {}).get("project_name")
                    if not p_name: p_name = data.get("project_name", "æœªçŸ¥é¡¹ç›®")
                    
                    matches.append({
                        "id": rid,
                        "project_name": p_name,
                        "sales_rep": data.get("sales_rep", "æœªçŸ¥"),
                        "distance": dist
                    })
                except: pass
        return matches
