import os

# --- æ ¸å¿ƒæ‹¦æˆªï¼šå¿…é¡»åœ¨æ‰€æœ‰ sentence_transformers å¯¼å…¥ä¹‹å‰è®¾ç½® ---
# è¿™è¦æ˜¯å†ä¸çµï¼Œè€å¤§å“¥ç›´æ¥å»æ²ˆé˜³å¤§è¡—è·³å¤§ç»³ï¼
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
os.environ["HTTP_PROXY"] = ""
os.environ["HTTPS_PROXY"] = ""

import chromadb
from sentence_transformers import SentenceTransformer
from pathlib import Path
import json

class VectorService:
    def __init__(self, db_path="data/vector_db", model_name="paraphrase-multilingual-MiniLM-L12-v2"):
        """
        æœ¬åœ°å‘é‡æœåŠ¡ï¼šé›†æˆäº† Embedding ç”Ÿæˆå’Œ ChromaDB å­˜å‚¨ã€‚
        é‡‡ç”¨åå°å¼‚æ­¥åŠ è½½ (Async Background Loading)ï¼Œå¯åŠ¨å³å¼€å§‹åŠ è½½ï¼Œä¸é˜»å¡ä¸»ç•Œé¢ã€‚
        """
        import threading
        
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self.model_name = model_name
        
        # å†…éƒ¨çŠ¶æ€
        self.model = None
        self.client = None
        self.collection = None
        
        # çº¿ç¨‹åŒæ­¥æ§åˆ¶
        self._init_event = threading.Event()
        self._init_error = None
        
        # å¯åŠ¨åå°åŠ è½½çº¿ç¨‹
        print("ğŸš€ [VectorService] å¯åŠ¨åå°åŠ è½½çº¿ç¨‹...")
        loader_thread = threading.Thread(target=self._background_loader, daemon=True)
        loader_thread.start()

    def _background_loader(self):
        """
        åå°çº¿ç¨‹ï¼šé»˜é»˜åœ°æŠŠæ¨¡å‹å’Œæ•°æ®åº“åŠ è½½å¥½
        """
        try:
            print("â³ [VectorService] åå°æ­£åœ¨åŠ è½½ Embedding æ¨¡å‹...")
            # 1. åŠ è½½æ¨¡å‹
            self.model = SentenceTransformer(self.model_name)
            
            print("â³ [VectorService] åå°æ­£åœ¨è¿æ¥ ChromaDB...")
            # 2. è¿æ¥æ•°æ®åº“
            self.client = chromadb.PersistentClient(path=str(self.db_path))
            self.collection = self.client.get_or_create_collection(name="sales_knowledge")
            
            print("âœ… [VectorService] å‘é‡å¼•æ“åå°åŠ è½½å®Œæˆï¼")
        except Exception as e:
            print(f"âŒ [VectorService] åˆå§‹åŒ–å¤±è´¥: {e}")
            self._init_error = e
        finally:
            # æ— è®ºæˆåŠŸå¤±è´¥ï¼Œéƒ½è¦é€šçŸ¥ä¸»çº¿ç¨‹ï¼ˆé¿å…æ­»é”ï¼‰
            self._init_event.set()

    def _ensure_initialized(self):
        """
        ç¡®ä¿å·²åˆå§‹åŒ–ã€‚å¦‚æœè¿˜åœ¨åŠ è½½ï¼Œå°±ç­‰ä¸€ä¼šå„¿ã€‚
        """
        if not self._init_event.is_set():
            print("âš ï¸ [VectorService] è¯·æ±‚è¿‡æ—©ï¼Œæ­£åœ¨ç­‰å¾…å¼•æ“å°±ç»ª...")
            self._init_event.wait() # <--- åªæœ‰è¿™é‡Œä¼šé˜»å¡
        
        if self._init_error:
            raise RuntimeError(f"VectorService failed to initialize: {self._init_error}")

    def status(self):
        if self._init_error:
            return "Error"
        return "Ready" if self._init_event.is_set() else "Loading..."

    def _format_record(self, record: dict) -> str:
        cust = record.get("customer_info", {})
        opp = record.get("project_opportunity", {})
        
        text = f"è®°å½•ç±»å‹: {record.get('record_type')}; "
        text += f"é”€å”®: {record.get('sales_rep')}; "
        text += f"æ‘˜è¦: {record.get('summary')}; "
        text += f"å®¢æˆ·: {cust.get('name')} æ¥è‡ª {cust.get('company')}; "
        text += f"é¡¹ç›®: {opp.get('project_name')} é¢„ç®— {opp.get('budget')} é˜¶æ®µ {opp.get('stage')}; "
        text += f"å…³é”®ç‚¹: {', '.join(record.get('key_points', []))}"
        return text

    def add_record(self, record_id: int, record_data: dict):
        self._ensure_initialized() # <--- ç¡®ä¿å°±ç»ª
        content_text = self._format_record(record_data)
        embedding = self.model.encode(content_text).tolist()
        
        # --- è™å“¥å‡çº§ï¼šå…ƒæ•°æ®æ‹†è§£ (Metadata Extraction) ---
        # æŠŠå…³é”®å­—æ®µæ‹†å‡ºæ¥å•ç‹¬å­˜ï¼Œæ–¹ä¾¿ä»¥ååšç²¾ç¡®ç­›é€‰ (Where Filter)
        # æ³¨æ„ï¼šChromaçš„metadataåªæ”¯æŒ str, int, float, bool
        
        # è·å–é¡¹ç›®åç§° (å…¼å®¹å¤šå±‚çº§)
        p_name = record_data.get("project_opportunity", {}).get("project_name")
        if not p_name: p_name = record_data.get("project_name", "æœªå‘½å")
        
        # è·å–é˜¶æ®µ (å…¼å®¹å¤šå±‚çº§)
        stage = record_data.get("opportunity_stage")
        if not stage: stage = record_data.get("project_opportunity", {}).get("opportunity_stage", "")
        
        meta = {
            "json_data": json.dumps(record_data, ensure_ascii=False),
            "sales_rep": str(record_data.get("sales_rep", "æœªçŸ¥")),  # é”€å”®ä¸“æ 
            "record_type": str(record_data.get("record_type", "å•†æœº")), # ç±»å‹
            "project_name": str(p_name), # é¡¹ç›®å
            "stage": str(stage) # é˜¶æ®µ
        }

        # ä½¿ç”¨ upsertï¼Œå¦‚æœ ID å­˜åœ¨å°±æ›´æ–°ï¼Œä¸å­˜åœ¨å°±æ–°å¢
        self.collection.upsert(
            embeddings=[embedding],
            documents=[content_text],
            metadatas=[meta],
            ids=[str(record_id)]
        )

    def delete_record(self, record_id: str):
        """
        ä»å‘é‡åº“ä¸­å½»åº•åˆ é™¤æŒ‡å®š ID çš„è®°å½•ã€‚
        """
        self._ensure_initialized()
        try:
            self.collection.delete(ids=[str(record_id)])
            return True
        except Exception as e:
            # å’±ä¹Ÿä¸å±å£°ï¼Œå°±åœ¨å¿ƒé‡Œè®°ä¸ªè¿‡
            # print(f"Vector delete warning: {e}")
            return False

    def reset_db(self):
        """
        ğŸ”¥ åˆ åº“è·‘è·¯...å•Šä¸æ˜¯ï¼Œæ¸…ç©ºé‡ç½®ï¼
        æ…ç”¨ï¼è¿™ä¼šæŠŠæ‰€æœ‰å­˜è¿›å»çš„å‘é‡å…¨å¹²æ‰ã€‚
        """
        self._ensure_initialized()
        try:
            self.client.delete_collection("sales_knowledge")
            self.collection = self.client.get_or_create_collection(name="sales_knowledge")
            return True
        except Exception as e:
            print(f"Reset failed: {e}")
            return False

    def search(self, query: str, top_k=5, where_filter: dict = None):
        """
        è¯­ä¹‰æœç´¢ + å­—æ®µè¿‡æ»¤
        where_filter: æ¯”å¦‚ {"sales_rep": "å¼ ä¸‰"}ï¼Œè®©å®ƒåªåœ¨å¼ ä¸‰çš„è®°å½•é‡Œæ‰¾ã€‚
        """
        self._ensure_initialized() # <--- ç¡®ä¿å°±ç»ª
        query_embedding = self.model.encode(query).tolist()
        
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            where=where_filter  # <--- åŠ ä¸Šè¿™å¥ï¼Œç²¾å‡†åˆ¶å¯¼ï¼
        )
        
        history_snippets = []
        if results and "metadatas" in results:
            for meta_list in results["metadatas"]:
                for meta in meta_list:
                    history_snippets.append(json.loads(meta["json_data"]))
        return history_snippets

    def search_projects(self, project_name: str, top_k=3, threshold=1.2):
        """
        ä¸“é—¨æœç´¢ç›¸ä¼¼çš„é¡¹ç›®åã€‚
        è¿”å›æ ¼å¼: [{"id": "...", "project_name": "...", "score": 0.85}, ...]
        threshold: è·ç¦»é˜ˆå€¼ (L2è·ç¦»)ï¼Œè¶Šå°è¶Šç›¸ä¼¼ã€‚é»˜è®¤ 1.2ï¼Œè¶…è¿‡è¿™ä¸ªå€¼çš„ä¸¢å¼ƒã€‚
        """
        self._ensure_initialized() # <--- ç¡®ä¿å°±ç»ª
        query_embedding = self.model.encode(project_name).tolist()
        
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
        )
        
        matches = []
        if results and "metadatas" in results:
            ids = results["ids"][0]
            metadatas = results["metadatas"][0]
            # Chroma é»˜è®¤ L2 è·ç¦»ï¼š0æ˜¯å®Œå…¨ä¸€æ ·ï¼Œ2æ˜¯å®Œå…¨ç›¸åã€‚
            # ä¸€èˆ¬æ¥è¯´ï¼Œ< 1.0 æ˜¯æ¯”è¾ƒç›¸å…³çš„ï¼Œ> 1.5 åŸºæœ¬å°±æ˜¯ççŒœäº†ã€‚
            distances = results["distances"][0] if "distances" in results else [0]*len(ids)
            
            for rid, meta, dist in zip(ids, metadatas, distances):
                # æ ¸å¿ƒè¿‡æ»¤ï¼šè·ç¦»å¤ªè¿œçš„ä¸€è„šè¸¢å¼€
                if dist > threshold:
                    continue

                try:
                    data = json.loads(meta["json_data"])
                    p_name = data.get("project_opportunity", {}).get("project_name")
                    if not p_name: p_name = data.get("project_name", "æœªçŸ¥é¡¹ç›®")
                    
                    # ç®€å•å»é‡é€»è¾‘å¯ä»¥åœ¨ controller åšï¼Œè¿™é‡Œåªç®¡åæ•°æ®
                    matches.append({
                        "id": rid,
                        "project_name": p_name,
                        "distance": dist
                    })
                except: pass
        return matches