import configparser
import json
import datetime
import re
import os
from pathlib import Path
from src.services.llm_service import (
    analyze_text, refine_sales_data, polish_text, 
    update_sales_data, is_sales_content, classify_intent, query_sales_data, summarize_text
)
from src.services.asr_service import transcribe_audio
from src.services.vector_service import VectorService

class LinkSellController:
    def __init__(self, config_path="config/config.ini"):
        self.config = configparser.ConfigParser()
        self.config_path = Path(config_path)
        if self.config_path.exists():
            self.config.read(self.config_path)
        
        # 1. è®¾ç½®å…¨å±€ç¯å¢ƒå˜é‡ä¸é»˜è®¤è®°å½•è€…
        hf_endpoint = self.config.get("global", "hf_endpoint", fallback=None)
        if hf_endpoint:
            os.environ["HF_ENDPOINT"] = hf_endpoint
        
        self.default_recorder = self.config.get("global", "default_recorder", fallback="é™ˆä¸€éª")
            
        self.api_key = self.config.get("doubao", "api_key", fallback=None)
        self.endpoint_id = self.config.get("doubao", "analyze_endpoint", fallback=None)
        
        # ASR Config
        self.asr_app_id = self.config.get("asr", "app_id", fallback=None)
        self.asr_token = self.config.get("asr", "access_token", fallback=None)
        self.asr_resource = self.config.get("asr", "resource_id", fallback="volc.seedasr.auc")
        if self.asr_resource == "volc.bigasr.sauc.duration":
             self.asr_resource = "volc.seedasr.auc"

        # 2. åŠ è½½å•†æœºé˜¶æ®µæ˜ å°„
        self.stage_map = {}
        if self.config.has_section("opportunity_stages"):
            self.stage_map = {k: v for k, v in self.config.items("opportunity_stages")}

        # 3. åˆå§‹åŒ–æœ¬åœ°å‘é‡åº“
        try:
            self.vector_service = VectorService()
        except Exception as e:
            print(f"[yellow]è­¦å‘Šï¼šæœ¬åœ°å‘é‡æ¨¡å‹åŠ è½½å¤±è´¥({e})ï¼Œå°†å›é€€åˆ°æ™®é€šæŸ¥è¯¢æ¨¡å¼ã€‚[/yellow]")
            self.vector_service = None

    def validate_llm_config(self):
        return bool(self.api_key and self.endpoint_id and "YOUR_" not in self.api_key)

    def validate_asr_config(self):
        return bool(self.asr_app_id and self.asr_token and "YOUR_" not in self.asr_token)

    def transcribe(self, audio_file, debug=False):
        if not self.validate_asr_config():
            raise ValueError("ASR Configuration Invalid")
        return transcribe_audio(audio_file, self.asr_app_id, self.asr_token, self.asr_resource, debug=debug)

    def polish(self, text):
        if not self.validate_llm_config():
            raise ValueError("LLM Configuration Invalid")
        return polish_text(text, self.api_key, self.endpoint_id)

    def analyze(self, text):
        if not self.validate_llm_config():
            raise ValueError("LLM Configuration Invalid")
        return analyze_text(text, self.api_key, self.endpoint_id)

    def identify_intent(self, text):
        """è¯†åˆ«æ„å›¾ï¼šANALYZE, QUERY, OTHER"""
        if not self.validate_llm_config():
            return "ANALYZE"
        return classify_intent(text, self.api_key, self.endpoint_id)

    def search_opportunities(self, keyword):
        """æ ¹æ®å…³é”®å­—æ¨¡ç³Šæœç´¢å·²æœ‰çš„é¡¹ç›®åç§°ï¼Œè¿”å› (é¡¹ç›®å, é”€å”®) åˆ—è¡¨ã€‚"""
        data_file_path = Path(self.config.get("storage", "data_file", fallback="data/sales_data.json"))
        if not data_file_path.exists():
            return []
        
        with open(data_file_path, "r", encoding="utf-8") as f:
            try: db_data = json.load(f)
            except: db_data = []
        
        # åŒ¹é…ç»“æœï¼šåŒ…å«é¡¹ç›®åå’Œé”€å”®äºº
        matches = []
        for p in db_data:
            p_name = p.get("project_name", "")
            if keyword.lower() in p_name.lower():
                matches.append({
                    "name": p_name,
                    "sales_rep": p.get("sales_rep", "æœªçŸ¥")
                })
        return matches

    def handle_query(self, query_text):
        if not self.validate_llm_config():
            return "__ERROR_CONFIG__"
            
        if self.vector_service:
            history = self.vector_service.search(query_text, top_k=5)
        else:
            data_file_path = Path(self.config.get("storage", "data_file", fallback="data/sales_data.json"))
            history = []
            if data_file_path.exists():
                with open(data_file_path, "r", encoding="utf-8") as f:
                    try:
                        full_db = json.load(f)
                        history = full_db[-10:]
                    except: pass
        
        if not history:
            return "__EMPTY_DB__"
            
        return query_sales_data(query_text, history, self.api_key, self.endpoint_id)

    def check_is_sales(self, text):
        if not self.validate_llm_config():
            return True
        return is_sales_content(text, self.api_key, self.endpoint_id)

    def get_missing_fields(self, data):
        if "project_opportunity" not in data:
            data["project_opportunity"] = {}

        required_config = {
            "sales_rep": ("ğŸ‘¨â€ğŸ’¼ æˆ‘æ–¹é”€å”®", None),
            "opportunity_stage": ("ğŸ“ˆ å•†æœºé˜¶æ®µ (1:éœ€æ±‚ç¡®è®¤ 2:æ²Ÿé€šäº¤æµ 3:å•†åŠ¡è°ˆåˆ¤ 4:ç­¾è®¢åˆåŒ)", "project_opportunity"),
            "timeline": ("â±ï¸ æ—¶é—´èŠ‚ç‚¹", "project_opportunity"),
            "budget": ("ğŸ’° é¢„ç®—é‡‘é¢", "project_opportunity"),
            "procurement_process": ("ğŸ“ é‡‡è´­æµç¨‹", "project_opportunity"),
            "competitors": ("âš”ï¸ ç«äº‰å¯¹æ‰‹", "project_opportunity"),
            "technical_staff": ("ğŸ§‘â€ğŸ’» æˆ‘æ–¹æŠ€æœ¯äººå‘˜", "project_opportunity"),
            "payment_terms": ("ğŸ’³ ä»˜æ¬¾æ–¹å¼", "project_opportunity")
        }
        
        missing = {}
        for field_key, (field_name, parent_key) in required_config.items():
            target_dict = data.get(parent_key) if parent_key else data
            val = target_dict.get(field_key) if target_dict else None
            is_missing = False
            if val is None: is_missing = True
            elif isinstance(val, str) and (not val.strip() or val in ["æœªçŸ¥", "æœªæŒ‡å®š", "N/A"]): is_missing = True
            elif isinstance(val, list) and not val: is_missing = True
            
            if is_missing:
                missing[field_key] = (field_name, parent_key)
        return missing

    def refine(self, data, supplements):
        return refine_sales_data(data, supplements, self.api_key, self.endpoint_id)

    def update(self, data, instruction):
        return update_sales_data(data, instruction, self.api_key, self.endpoint_id)

    def save(self, record, raw_content=""):
        """
        ä¿å­˜å•†æœºä¿¡æ¯ï¼šä»¥é¡¹ç›®åä¸ºå”¯ä¸€æ ‡è¯†ï¼Œèšåˆå­˜å‚¨ã€‚
        raw_content: polish_text.txt æ¶¦è‰²åçš„åŸå§‹æ–‡å­—ã€‚
        """
        data_file_path = Path(self.config.get("storage", "data_file", fallback="data/sales_data.json"))
        
        # 1. æ–‡å­—æç‚¼ (å¦‚æœæ¶¦è‰²æ–‡æœ¬ > 500å­—åˆ™ç”Ÿæˆæ‘˜è¦)
        note_text = raw_content if raw_content else record.get("summary", "")
        if len(note_text) > 500:
            note_text = summarize_text(note_text, self.api_key, self.endpoint_id)

        # 2. è¯»å–ä¸»åº“
        if data_file_path.exists():
            with open(data_file_path, "r", encoding="utf-8") as f:
                try: db_data = json.load(f)
                except: db_data = []
        else:
            db_data = []
            data_file_path.parent.mkdir(parents=True, exist_ok=True)

        now = datetime.datetime.now()
        proj_info = record.get("project_opportunity", {})
        proj_name = proj_info.get("project_name", "æœªå‘½åé¡¹ç›®")
        
        # 3. æ„é€ æœ¬æ¬¡è®°å½•çš„å°è®° (å«æ—¶é—´ã€è®°å½•è€…ã€ç²¾ä¿®æ–‡æœ¬)
        new_log_entry = {
            "time": now.strftime("%Y-%m-%d %H:%M:%S"),
            "recorder": self.default_recorder,
            "content": note_text
        }

        # 4. å¯»æ‰¾æˆ–åˆ›å»ºå•†æœºé¡¹
        target_proj = next((p for p in db_data if p.get("project_name") == proj_name), None)
        
        if target_proj:
            # æ›´æ–°å•†æœºå±æ€§
            for key, val in proj_info.items():
                if val is not None and val != "":
                    target_proj[key] = val
            target_proj.setdefault("customer_info", {}).update(record.get("customer_info", {}))
            # è¿½åŠ åˆ°è®°å½•å¿—æ•°ç»„
            target_proj.setdefault("record_logs", []).append(new_log_entry)
            target_proj["updated_at"] = now.isoformat()
            record_id = target_proj.get("id", 0)
        else:
            # æ–°å»ºå•†æœº
            new_proj = proj_info.copy()
            new_proj["project_name"] = proj_name
            new_proj["customer_info"] = record.get("customer_info", {})
            new_proj["record_logs"] = [new_log_entry]
            new_proj["created_at"] = now.isoformat()
            new_proj["updated_at"] = now.isoformat()
            record_id = len(db_data) + 1
            new_proj["id"] = record_id
            db_data.append(new_proj)
        
        with open(data_file_path, "w", encoding="utf-8") as f:
            json.dump(db_data, f, ensure_ascii=False, indent=2)
            
        # 5. å‘é‡åº“åŒæ­¥
        if self.vector_service:
            try:
                self.vector_service.add_record(record_id, record)
            except: pass
            
        return record_id, "data/records/backup.json"

    def get_all_opportunities(self):
        """è·å–æ‰€æœ‰å•†æœºè®°å½•"""
        data_file_path = Path(self.config.get("storage", "data_file", fallback="data/sales_data.json"))
        if not data_file_path.exists(): return []
        with open(data_file_path, "r", encoding="utf-8") as f:
            try: return json.load(f)
            except: return []

    def get_opportunity_by_id(self, record_id):
        """æ ¹æ® ID è·å–å•æ¡å•†æœº"""
        all_data = self.get_all_opportunities()
        # JSON ä¸­è¯»å–çš„ ID å¯èƒ½æ˜¯ intï¼Œä¼ å…¥çš„å¯èƒ½æ˜¯ strï¼Œåšä¸ªå…¼å®¹
        return next((item for item in all_data if str(item.get("id")) == str(record_id)), None)

    def delete_opportunity(self, record_id):
        """æ ¹æ® ID åˆ é™¤å•†æœº"""
        all_data = self.get_all_opportunities()
        initial_len = len(all_data)
        all_data = [item for item in all_data if str(item.get("id")) != str(record_id)]
        
        if len(all_data) < initial_len:
            data_file_path = Path(self.config.get("storage", "data_file", fallback="data/sales_data.json"))
            with open(data_file_path, "w", encoding="utf-8") as f:
                json.dump(all_data, f, ensure_ascii=False, indent=2)
            
            # è¡¥åˆ€ï¼šæŠŠå‘é‡åº“é‡Œçš„å¹½çµä¹Ÿç»™ç­äº†
            if self.vector_service:
                self.vector_service.delete_record(record_id)
            
            return True
        return False

    def overwrite_opportunity(self, new_data):
        """
        å®Œå…¨è¦†ç›–æ›´æ–°ä¸€ä¸ªå•†æœºè®°å½•ï¼ˆç”¨äºç¼–è¾‘æ¨¡å¼ï¼‰ã€‚
        ä¸åŒäº save çš„â€œè¿½åŠ æ¨¡å¼â€ï¼Œè¿™æ˜¯â€œé‡å†™æ¨¡å¼â€ã€‚
        """
        all_data = self.get_all_opportunities()
        record_id = new_data.get("id")
        
        if not record_id: return False
        
        updated = False
        for i, item in enumerate(all_data):
            if str(item.get("id")) == str(record_id):
                # ä¿æŒè®°å½•æ—¥å¿—ä¸ä¸¢å¤± (å¦‚æœ new_data é‡Œæ²¡æœ‰å¸¦å›æ¥ record_logs)
                if "record_logs" not in new_data and "record_logs" in item:
                    new_data["record_logs"] = item["record_logs"]
                
                # æ›´æ–°æ—¶é—´æˆ³
                new_data["updated_at"] = datetime.datetime.now().isoformat()
                
                all_data[i] = new_data
                updated = True
                break
        
        if updated:
            data_file_path = Path(self.config.get("storage", "data_file", fallback="data/sales_data.json"))
            with open(data_file_path, "w", encoding="utf-8") as f:
                json.dump(all_data, f, ensure_ascii=False, indent=2)
            
            # åŒæ­¥æ›´æ–°å‘é‡åº“
            if self.vector_service:
                 try: self.vector_service.add_record(record_id, new_data)
                 except: pass
            return True
        return False
