import configparser
import json
import datetime
import re
import os
from pathlib import Path
from src.services.llm_service import (
    analyze_text, refine_sales_data, polish_text, 
    update_sales_data, is_sales_content, classify_intent, query_sales_data
)
from src.services.asr_service import transcribe_audio
from src.services.vector_service import VectorService

class LinkSellController:
    def __init__(self, config_path="config/config.ini"):
        self.config = configparser.ConfigParser()
        self.config_path = Path(config_path)
        if self.config_path.exists():
            self.config.read(self.config_path)
        
        # 1. è®¾ç½®å…¨å±€ç¯å¢ƒå˜é‡ (è§£å†³æ¨¡å‹ä¸‹è½½é—®é¢˜)
        hf_endpoint = self.config.get("global", "hf_endpoint", fallback=None)
        if hf_endpoint:
            os.environ["HF_ENDPOINT"] = hf_endpoint
            
        self.api_key = self.config.get("doubao", "api_key", fallback=None)
        self.endpoint_id = self.config.get("doubao", "analyze_endpoint", fallback=None)
        
        # ASR Config
        self.asr_app_id = self.config.get("asr", "app_id", fallback=None)
        self.asr_token = self.config.get("asr", "access_token", fallback=None)
        self.asr_resource = self.config.get("asr", "resource_id", fallback="volc.seedasr.auc")
        if self.asr_resource == "volc.bigasr.sauc.duration":
             self.asr_resource = "volc.seedasr.auc"

        # 2. åˆå§‹åŒ–æœ¬åœ°å‘é‡åº“
        try:
            self.vector_service = VectorService()
        except Exception as e:
            print(f"[yellow]è­¦å‘Šï¼šæœ¬åœ°å‘é‡æ¨¡å‹åŠ è½½å¤±è´¥({{e}})é”›å›é€€åˆ°æ™®é€šæŸ¥è¯¢æ¨¡å¼ã€‚[/yellow]")
            self.vector_service = None

    def validate_llm_config(self):
        return bool(self.api_key and self.endpoint_id and "YOUR_" not in self.api_key)

    def validate_asr_config(self):
        return bool(self.asr_app_id and self.asr_token and "YOUR_" not in self.asr_token)

    def transcribe(self, audio_file, debug=False):
        if not self.validate_asr_config():
            raise ValueError("ASR Configuration Invalid")
        return transcribe_audio(audio_file, self.asr_app_id, self.asr_token, self.asr_resource, debug=debug)

    def polish(self, text):
        if not self.validate_llm_config():
            raise ValueError("LLM Configuration Invalid")
        return polish_text(text, self.api_key, self.endpoint_id)

    def analyze(self, text):
        if not self.validate_llm_config():
            raise ValueError("LLM Configuration Invalid")
        return analyze_text(text, self.api_key, self.endpoint_id)

    def get_intent(self, text):
        """åˆ¤æ–­æ„å›¾ï¼šANALYZE, QUERY, OTHER"""
        if not self.validate_llm_config():
            return "ANALYZE"
        return classify_intent(text, self.api_key, self.endpoint_id)

    def handle_query(self, query_text):
        """æ‰§è¡ŒæŸ¥è¯¢é€»è¾‘ï¼šå…ˆä»å‘é‡åº“æ£€ç´¢æœ€ç›¸å…³çš„ä¸Šä¸‹æ–‡ï¼Œå†ç”± LLM å›ç­”ã€‚"""
        if not self.validate_llm_config():
            return "æ— æ³•æ‰§è¡ŒæŸ¥è¯¢ï¼šé…ç½®æ— æ•ˆã€‚"
            
        if self.vector_service:
            # è¯­ä¹‰æœç´¢ï¼šè–…å‡ºæœ€ç›¸å…³çš„ 5 æ¡è®°å½•
            history = self.vector_service.search(query_text, top_k=5)
        else:
            # å›é€€æ¨¡å¼ï¼šè¯»å– JSON åº“æœ€å 10 æ¡
            data_file_path = Path(self.config.get("storage", "data_file", fallback="data/sales_data.json"))
            history = []
            if data_file_path.exists():
                with open(data_file_path, "r", encoding="utf-8") as f:
                    try:
                        full_db = json.load(f)
                        history = full_db[-10:]
                    except: pass
        
        if not history:
            return "ç›®å‰æ•°æ®åº“é‡Œè¿˜æ˜¯ç©ºçš„ï¼Œè€å¤§å“¥ä¹Ÿæ²¡æ³•å‡­ç©ºç»™ä½ å˜å‡ºæ•°æ®æ¥å•Šï¼"
            
        return query_sales_data(query_text, history, self.api_key, self.endpoint_id)

    def check_is_sales(self, text):
        """åˆ¤æ–­å†…å®¹æ˜¯å¦ä¸ºé”€å”®ç›¸å…³ã€‚"""
        if not self.validate_llm_config():
            return True
        return is_sales_content(text, self.api_key, self.endpoint_id)

    def get_missing_fields(self, data):
        """è¯†åˆ«ç¼ºå¤±çš„å¿…å¡«å­—æ®µã€‚"""
        if "project_opportunity" not in data:
            data["project_opportunity"] = {}

        required_config = {
            "sales_rep": ("ğŸ‘¨â€ğŸ’¼ æˆ‘æ–¹é”€å”®", None),
            "timeline": ("â±ï¸ æ—¶é—´èŠ‚ç‚¹", "project_opportunity"),
            "budget": ("ğŸ’° é¢„ç®—é‡‘é¢", "project_opportunity"),
            "procurement_process": ("ğŸ“ é‡‡è´­æµç¨‹", "project_opportunity"),
            "competitors": ("âš”ï¸ ç«äº‰å¯¹æ‰‹", "project_opportunity"),
            "tech_stack": ("ğŸ› ï¸ æˆ‘æ–¹å‚ä¸æŠ€æœ¯", "project_opportunity"),
            "payment_terms": ("ğŸ’³ ä»˜æ¬¾æ–¹å¼", "project_opportunity")
        }
        
        missing = {}
        for field_key, (field_name, parent_key) in required_config.items():
            target_dict = data.get(parent_key) if parent_key else data
            val = target_dict.get(field_key) if target_dict else None
            
            is_missing = False
            if val is None: is_missing = True
            elif isinstance(val, str) and (not val.strip() or val in ["æœªçŸ¥", "æœªæŒ‡å®š", "N/A"]): is_missing = True
            elif isinstance(val, list) and not val: is_missing = True
            
            if is_missing:
                missing[field_key] = (field_name, parent_key)
        return missing

    def refine(self, data, supplements):
        return refine_sales_data(data, supplements, self.api_key, self.endpoint_id)

    def update(self, data, instruction):
        return update_sales_data(data, instruction, self.api_key, self.endpoint_id)

    def save(self, record):
        """ä¿å­˜è®°å½•ï¼šåŒå†™æ¨¡å¼ (JSON DB + Vector DB)ã€‚"""
        data_file_path = Path(self.config.get("storage", "data_file", fallback="data/sales_data.json"))
        
        # 1. å­˜å…¥ JSON ä¸»åº“
        if data_file_path.exists():
            with open(data_file_path, "r", encoding="utf-8") as f:
                try: db_data = json.load(f)
                except: db_data = []
        else:
            db_data = []
            data_file_path.parent.mkdir(parents=True, exist_ok=True)

        now = datetime.datetime.now()
        record["created_at"] = now.isoformat()
        record_id = len(db_data) + 1
        record["id"] = record_id
        db_data.append(record)
        
        with open(data_file_path, "w", encoding="utf-8") as f:
            json.dump(db_data, f, ensure_ascii=False, indent=2)
            
        # 2. å­˜å…¥å‘é‡åº“
        if self.vector_service:
            try:
                self.vector_service.add_record(record_id, record)
            except Exception as e:
                print(f"[yellow]å‘é‡å­˜å…¥å¤±è´¥ï¼š{{e}}[/yellow]")
            
        # 3. å¤‡ä»½ç‹¬ç«‹æ–‡ä»¶
        proj_name = record.get("project_opportunity", {}).get("project_name", "æœªå‘½åé¡¹ç›®")
        safe_proj_name = re.sub(r'[\\/*?:",<>|]', "", str(proj_name)).strip().replace(" ", "_")
        time_str = now.strftime("%Y%m%d_%H%M%S")
        filename = f"{safe_proj_name}-{time_str}.json"
        
        records_dir = data_file_path.parent / "records"
        records_dir.mkdir(parents=True, exist_ok=True)
        record_path = records_dir / filename
        
        with open(record_path, "w", encoding="utf-8") as f:
            json.dump(record, f, ensure_ascii=False, indent=2)
            
        return record["id"], str(record_path)
